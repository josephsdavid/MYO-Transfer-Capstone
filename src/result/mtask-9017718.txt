2020-02-03 23:08:50.985686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-03 23:08:51.592792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:15:00.0
2020-02-03 23:08:51.594872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:16:00.0
2020-02-03 23:08:51.597015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3a:00.0
2020-02-03 23:08:51.599035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3b:00.0
2020-02-03 23:08:51.601036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:89:00.0
2020-02-03 23:08:51.603025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:8a:00.0
2020-02-03 23:08:51.605010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b2:00.0
2020-02-03 23:08:51.607003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b3:00.0
2020-02-03 23:08:51.608083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-03 23:08:51.611447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-03 23:08:51.613759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-03 23:08:51.615120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-03 23:08:51.617658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-03 23:08:51.619780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-03 23:08:51.624785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-03 23:08:51.655993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-02-03 23:08:51.657917: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-02-03 23:08:51.668053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz
2020-02-03 23:08:51.669269: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55555972d740 executing computations on platform Host. Devices:
2020-02-03 23:08:51.669288: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-02-03 23:08:52.986524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:15:00.0
2020-02-03 23:08:52.988556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:16:00.0
2020-02-03 23:08:52.990528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3a:00.0
2020-02-03 23:08:52.992506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3b:00.0
2020-02-03 23:08:52.994499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:89:00.0
2020-02-03 23:08:52.996452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:8a:00.0
2020-02-03 23:08:52.998410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b2:00.0
2020-02-03 23:08:53.000358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b3:00.0
2020-02-03 23:08:53.000408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-03 23:08:53.000419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-03 23:08:53.000429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-03 23:08:53.000438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-03 23:08:53.000447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-03 23:08:53.000457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-03 23:08:53.000467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-03 23:08:53.031397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-02-03 23:08:53.031436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-03 23:08:53.049898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-03 23:08:53.049915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 5 6 7 
2020-02-03 23:08:53.049927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y Y Y Y Y 
2020-02-03 23:08:53.049933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y Y Y Y Y 
2020-02-03 23:08:53.049938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y Y Y Y Y 
2020-02-03 23:08:53.049943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N Y Y Y Y 
2020-02-03 23:08:53.049948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   Y Y Y Y N Y Y Y 
2020-02-03 23:08:53.049953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 5:   Y Y Y Y Y N Y Y 
2020-02-03 23:08:53.049958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 6:   Y Y Y Y Y Y N Y 
2020-02-03 23:08:53.049964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 7:   Y Y Y Y Y Y Y N 
2020-02-03 23:08:53.070376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30553 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:15:00.0, compute capability: 7.0)
2020-02-03 23:08:53.074979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30553 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0)
2020-02-03 23:08:53.079439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30553 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0)
2020-02-03 23:08:53.083876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30553 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
2020-02-03 23:08:53.088285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 30553 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)
2020-02-03 23:08:53.092720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 30553 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
2020-02-03 23:08:53.097322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 30553 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0)
2020-02-03 23:08:53.101713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 30553 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0)
2020-02-03 23:08:53.104857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55555e92bcd0 executing computations on platform CUDA. Devices:
2020-02-03 23:08:53.104873: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104879: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104884: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104889: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104898: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104903: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104908: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.104913: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-02-03 23:08:53.110778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:15:00.0
2020-02-03 23:08:53.112751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:16:00.0
2020-02-03 23:08:53.114740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 2 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3a:00.0
2020-02-03 23:08:53.116692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 3 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3b:00.0
2020-02-03 23:08:53.118621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 4 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:89:00.0
2020-02-03 23:08:53.120552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 5 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:8a:00.0
2020-02-03 23:08:53.122488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 6 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b2:00.0
2020-02-03 23:08:53.124415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 7 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:b3:00.0
2020-02-03 23:08:53.124437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-03 23:08:53.124448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-03 23:08:53.124457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-03 23:08:53.124466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-03 23:08:53.124474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-03 23:08:53.124483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-03 23:08:53.124492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-03 23:08:53.155303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-02-03 23:08:53.156315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-03 23:08:53.156324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3 4 5 6 7 
2020-02-03 23:08:53.156330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y Y Y Y Y Y Y 
2020-02-03 23:08:53.156335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N Y Y Y Y Y Y 
2020-02-03 23:08:53.156340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   Y Y N Y Y Y Y Y 
2020-02-03 23:08:53.156345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   Y Y Y N Y Y Y Y 
2020-02-03 23:08:53.156351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 4:   Y Y Y Y N Y Y Y 
2020-02-03 23:08:53.156356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 5:   Y Y Y Y Y N Y Y 
2020-02-03 23:08:53.156361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 6:   Y Y Y Y Y Y N Y 
2020-02-03 23:08:53.156366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 7:   Y Y Y Y Y Y Y N 
2020-02-03 23:08:53.174718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 30553 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:15:00.0, compute capability: 7.0)
2020-02-03 23:08:53.176692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 30553 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0)
2020-02-03 23:08:53.178660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 30553 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0)
2020-02-03 23:08:53.180622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 30553 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
2020-02-03 23:08:53.182577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:4 with 30553 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)
2020-02-03 23:08:53.184521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:5 with 30553 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
2020-02-03 23:08:53.186472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:6 with 30553 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0)
2020-02-03 23:08:53.188425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:7 with 30553 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0)
2020-02-03 23:11:17.953485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Starting load of 1/10 .mat files
Starting load of 2/10 .mat files
Starting load of 3/10 .mat files
Starting load of 4/10 .mat files
Starting load of 5/10 .mat files
Starting load of 6/10 .mat files
Starting load of 7/10 .mat files
Starting load of 8/10 .mat files
Starting load of 9/10 .mat files
Starting load of 10/10 .mat files
[Step 0] 
exData (10, 130000, 8)
labels (10, 130000, 1)
[Step 1 ==> processing] Shape of emg: (10, 130000, 8)
[Step 1 ==> processing] Shape of labels: (10, 130000, 1)
[Step 1 ==> processing] Shape of reps: (10, 130000, 1)
[Step 1 ==> processing] Shape of subjects: (10, 130000, 1)
[Step 2 ==> augment] Shape of emg: (10, 130000, 8)
[Step 2 ==> augment] Shape of labels: (10, 130000, 1)
[Step 2 ==> augment] Shape of reps: (10, 130000, 1)
[Step 2 ==> augment] Shape of subjects: (10, 130000, 1)
[Step 3 ==> moveaxis] Shape of emg: (10, 25990, 8, 52)
[Step 3 ==> moveaxis] Shape of labels: (10, 25990, 1, 52)
[Step 3 ==> moveaxis] Shape of reps: (10, 25990, 1, 52)
[Step 3 ==> moveaxis] Shape of subjects: (10, 25990, 1, 52)
[Step 4 ==> scale] Shape of emg: (259900, 52, 8)
[Step 4 ==> scale] Shape of labels: (259900,)
[Step 3 ==> scale] Shape of reps: (259900,)
[Step 3 ==> scale] Shape of subjects: (259900,)
Starting load of 1/10 .mat files
Starting load of 2/10 .mat files
Starting load of 3/10 .mat files
Starting load of 4/10 .mat files
Starting load of 5/10 .mat files
Starting load of 6/10 .mat files
Starting load of 7/10 .mat files
Starting load of 8/10 .mat files
Starting load of 9/10 .mat files
Starting load of 10/10 .mat files
[Step 0] 
exData (10, 130000, 8)
labels (10, 130000, 1)
[Step 1 ==> processing] Shape of emg: (10, 130000, 8)
[Step 1 ==> processing] Shape of labels: (10, 130000, 1)
[Step 1 ==> processing] Shape of reps: (10, 130000, 1)
[Step 1 ==> processing] Shape of subjects: (10, 130000, 1)
[Step 2 ==> augment] Shape of emg: (10, 130000, 8)
[Step 2 ==> augment] Shape of labels: (10, 130000, 1)
[Step 2 ==> augment] Shape of reps: (10, 130000, 1)
[Step 2 ==> augment] Shape of subjects: (10, 130000, 1)
[Step 3 ==> moveaxis] Shape of emg: (10, 25990, 8, 52)
[Step 3 ==> moveaxis] Shape of labels: (10, 25990, 1, 52)
[Step 3 ==> moveaxis] Shape of reps: (10, 25990, 1, 52)
[Step 3 ==> moveaxis] Shape of subjects: (10, 25990, 1, 52)
[Step 4 ==> scale] Shape of emg: (259900, 52, 8)
[Step 4 ==> scale] Shape of labels: (259900,)
[Step 3 ==> scale] Shape of reps: (259900,)
[Step 3 ==> scale] Shape of subjects: (259900,)
(204800, 52, 8)
Train on 204800 samples, validate on 49152 samples
Epoch 1/1000
  4096/204800 [..............................] - ETA: 1:39:29 - loss: 113.6824 - classification_loss: 2.8447 - autoencoder_loss: 110.8378 - classification_accuracy: 0.0603  8192/204800 [>.............................] - ETA: 49:11 - loss: 110.6106 - classification_loss: 2.7183 - autoencoder_loss: 107.8923 - classification_accuracy: 0.2714   12288/204800 [>.............................] - ETA: 32:25 - loss: 112.8922 - classification_loss: 2.5563 - autoencoder_loss: 110.3359 - classification_accuracy: 0.3823 16384/204800 [=>............................] - ETA: 24:00 - loss: 113.5221 - classification_loss: 2.3799 - autoencoder_loss: 111.1422 - classification_accuracy: 0.4358 20480/204800 [==>...........................] - ETA: 18:58 - loss: 113.7564 - classification_loss: 2.2560 - autoencoder_loss: 111.5004 - classification_accuracy: 0.4688 24576/204800 [==>...........................] - ETA: 15:35 - loss: 113.6235 - classification_loss: 2.1781 - autoencoder_loss: 111.4454 - classification_accuracy: 0.4921 28672/204800 [===>..........................] - ETA: 13:10 - loss: 113.0487 - classification_loss: 2.1157 - autoencoder_loss: 110.9329 - classification_accuracy: 0.5095 32768/204800 [===>..........................] - ETA: 11:21 - loss: 113.1347 - classification_loss: 2.0583 - autoencoder_loss: 111.0764 - classification_accuracy: 0.5220 36864/204800 [====>.........................] - ETA: 9:56 - loss: 112.6090 - classification_loss: 2.0054 - autoencoder_loss: 110.6036 - classification_accuracy: 0.5318  40960/204800 [=====>........................] - ETA: 8:48 - loss: 112.3342 - classification_loss: 1.9625 - autoencoder_loss: 110.3717 - classification_accuracy: 0.5388 45056/204800 [=====>........................] - ETA: 7:52 - loss: 112.0750 - classification_loss: 1.9216 - autoencoder_loss: 110.1534 - classification_accuracy: 0.5457 49152/204800 [======>.......................] - ETA: 7:05 - loss: 112.2471 - classification_loss: 1.8877 - autoencoder_loss: 110.3594 - classification_accuracy: 0.5499 53248/204800 [======>.......................] - ETA: 6:25 - loss: 112.3295 - classification_loss: 1.8543 - autoencoder_loss: 110.4753 - classification_accuracy: 0.5539 57344/204800 [=======>......................] - ETA: 5:51 - loss: 112.1868 - classification_loss: 1.8252 - autoencoder_loss: 110.3617 - classification_accuracy: 0.5573 61440/204800 [========>.....................] - ETA: 5:21 - loss: 112.1256 - classification_loss: 1.7999 - autoencoder_loss: 110.3256 - classification_accuracy: 0.5597 65536/204800 [========>.....................] - ETA: 4:54 - loss: 112.2333 - classification_loss: 1.7753 - autoencoder_loss: 110.4580 - classification_accuracy: 0.5625 69632/204800 [=========>....................] - ETA: 4:31 - loss: 112.5204 - classification_loss: 1.7541 - autoencoder_loss: 110.7663 - classification_accuracy: 0.5648 73728/204800 [=========>....................] - ETA: 4:10 - loss: 112.3838 - classification_loss: 1.7306 - autoencoder_loss: 110.6532 - classification_accuracy: 0.5676 77824/204800 [==========>...................] - ETA: 3:51 - loss: 112.2588 - classification_loss: 1.7088 - autoencoder_loss: 110.5500 - classification_accuracy: 0.5703 81920/204800 [===========>..................] - ETA: 3:34 - loss: 112.2970 - classification_loss: 1.6909 - autoencoder_loss: 110.6062 - classification_accuracy: 0.5721 86016/204800 [===========>..................] - ETA: 3:19 - loss: 112.2211 - classification_loss: 1.6733 - autoencoder_loss: 110.5479 - classification_accuracy: 0.5742 90112/204800 [============>.................] - ETA: 3:05 - loss: 111.9479 - classification_loss: 1.6564 - autoencoder_loss: 110.2915 - classification_accuracy: 0.5762 94208/204800 [============>.................] - ETA: 2:51 - loss: 111.8569 - classification_loss: 1.6420 - autoencoder_loss: 110.2149 - classification_accuracy: 0.5774 98304/204800 [=============>................] - ETA: 2:39 - loss: 111.8953 - classification_loss: 1.6302 - autoencoder_loss: 110.2651 - classification_accuracy: 0.5781102400/204800 [==============>...............] - ETA: 2:28 - loss: 111.7357 - classification_loss: 1.6194 - autoencoder_loss: 110.1163 - classification_accuracy: 0.5787106496/204800 [==============>...............] - ETA: 2:18 - loss: 111.7622 - classification_loss: 1.6071 - autoencoder_loss: 110.1551 - classification_accuracy: 0.5801110592/204800 [===============>..............] - ETA: 2:08 - loss: 111.7954 - classification_loss: 1.5951 - autoencoder_loss: 110.2003 - classification_accuracy: 0.5814114688/204800 [===============>..............] - ETA: 1:59 - loss: 111.6298 - classification_loss: 1.5826 - autoencoder_loss: 110.0471 - classification_accuracy: 0.5831118784/204800 [================>.............] - ETA: 1:50 - loss: 111.8590 - classification_loss: 1.5730 - autoencoder_loss: 110.2860 - classification_accuracy: 0.5840122880/204800 [=================>............] - ETA: 1:42 - loss: 111.7559 - classification_loss: 1.5646 - autoencoder_loss: 110.1912 - classification_accuracy: 0.5848126976/204800 [=================>............] - ETA: 1:35 - loss: 111.8797 - classification_loss: 1.5563 - autoencoder_loss: 110.3234 - classification_accuracy: 0.5854131072/204800 [==================>...........] - ETA: 1:28 - loss: 111.9690 - classification_loss: 1.5487 - autoencoder_loss: 110.4203 - classification_accuracy: 0.5860135168/204800 [==================>...........] - ETA: 1:21 - loss: 111.8605 - classification_loss: 1.5411 - autoencoder_loss: 110.3194 - classification_accuracy: 0.5867139264/204800 [===================>..........] - ETA: 1:14 - loss: 111.9157 - classification_loss: 1.5351 - autoencoder_loss: 110.3807 - classification_accuracy: 0.5871143360/204800 [====================>.........] - ETA: 1:08 - loss: 111.9825 - classification_loss: 1.5285 - autoencoder_loss: 110.4540 - classification_accuracy: 0.5876147456/204800 [====================>.........] - ETA: 1:02 - loss: 111.9904 - classification_loss: 1.5222 - autoencoder_loss: 110.4682 - classification_accuracy: 0.5882151552/204800 [=====================>........] - ETA: 57s - loss: 111.9322 - classification_loss: 1.5165 - autoencoder_loss: 110.4157 - classification_accuracy: 0.5887 155648/204800 [=====================>........] - ETA: 51s - loss: 112.2002 - classification_loss: 1.5101 - autoencoder_loss: 110.6901 - classification_accuracy: 0.5895159744/204800 [======================>.......] - ETA: 46s - loss: 112.2401 - classification_loss: 1.5042 - autoencoder_loss: 110.7359 - classification_accuracy: 0.5902163840/204800 [=======================>......] - ETA: 41s - loss: 112.2718 - classification_loss: 1.4977 - autoencoder_loss: 110.7741 - classification_accuracy: 0.5911167936/204800 [=======================>......] - ETA: 36s - loss: 112.0409 - classification_loss: 1.4915 - autoencoder_loss: 110.5494 - classification_accuracy: 0.5920172032/204800 [========================>.....] - ETA: 31s - loss: 111.9017 - classification_loss: 1.4857 - autoencoder_loss: 110.4161 - classification_accuracy: 0.5928176128/204800 [========================>.....] - ETA: 27s - loss: 111.9943 - classification_loss: 1.4805 - autoencoder_loss: 110.5139 - classification_accuracy: 0.5933180224/204800 [=========================>....] - ETA: 23s - loss: 112.1361 - classification_loss: 1.4757 - autoencoder_loss: 110.6604 - classification_accuracy: 0.5940184320/204800 [==========================>...] - ETA: 19s - loss: 112.1801 - classification_loss: 1.4709 - autoencoder_loss: 110.7092 - classification_accuracy: 0.5945188416/204800 [==========================>...] - ETA: 14s - loss: 112.0944 - classification_loss: 1.4665 - autoencoder_loss: 110.6280 - classification_accuracy: 0.5952192512/204800 [===========================>..] - ETA: 11s - loss: 112.0136 - classification_loss: 1.4617 - autoencoder_loss: 110.5519 - classification_accuracy: 0.5958196608/204800 [===========================>..] - ETA: 7s - loss: 111.9158 - classification_loss: 1.4573 - autoencoder_loss: 110.4585 - classification_accuracy: 0.5963 200704/204800 [============================>.] - ETA: 3s - loss: 111.9465 - classification_loss: 1.4533 - autoencoder_loss: 110.4933 - classification_accuracy: 0.5967WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.10196 - momentum: 0.95 
204800/204800 [==============================] - 187s 911us/sample - loss: 111.8839 - classification_loss: 1.4490 - autoencoder_loss: 110.4349 - classification_accuracy: 0.5973 - val_loss: 120.9096 - val_classification_loss: 1.1840 - val_autoencoder_loss: 119.7256 - val_classification_accuracy: 0.6577
Epoch 2/1000
  4096/204800 [..............................] - ETA: 56s - loss: 111.8243 - classification_loss: 1.3084 - autoencoder_loss: 110.5159 - classification_accuracy: 0.6050  8192/204800 [>.............................] - ETA: 53s - loss: 108.9053 - classification_loss: 1.2854 - autoencoder_loss: 107.6199 - classification_accuracy: 0.6140 12288/204800 [>.............................] - ETA: 53s - loss: 111.3862 - classification_loss: 1.2755 - autoencoder_loss: 110.1107 - classification_accuracy: 0.6145 16384/204800 [=>............................] - ETA: 52s - loss: 112.2386 - classification_loss: 1.2775 - autoencoder_loss: 110.9611 - classification_accuracy: 0.6142 20480/204800 [==>...........................] - ETA: 50s - loss: 112.6286 - classification_loss: 1.2788 - autoencoder_loss: 111.3499 - classification_accuracy: 0.6146 24576/204800 [==>...........................] - ETA: 49s - loss: 112.5850 - classification_loss: 1.2741 - autoencoder_loss: 111.3110 - classification_accuracy: 0.6169 28672/204800 [===>..........................] - ETA: 48s - loss: 112.0800 - classification_loss: 1.2709 - autoencoder_loss: 110.8091 - classification_accuracy: 0.6186 32768/204800 [===>..........................] - ETA: 47s - loss: 112.2283 - classification_loss: 1.2662 - autoencoder_loss: 110.9621 - classification_accuracy: 0.6199 36864/204800 [====>.........................] - ETA: 46s - loss: 111.7602 - classification_loss: 1.2616 - autoencoder_loss: 110.4986 - classification_accuracy: 0.6209 40960/204800 [=====>........................] - ETA: 45s - loss: 111.5362 - classification_loss: 1.2612 - autoencoder_loss: 110.2749 - classification_accuracy: 0.6209 45056/204800 [=====>........................] - ETA: 44s - loss: 111.3220 - classification_loss: 1.2581 - autoencoder_loss: 110.0639 - classification_accuracy: 0.6216 49152/204800 [======>.......................] - ETA: 42s - loss: 111.5353 - classification_loss: 1.2592 - autoencoder_loss: 110.2761 - classification_accuracy: 0.6211 53248/204800 [======>.......................] - ETA: 41s - loss: 111.6566 - classification_loss: 1.2593 - autoencoder_loss: 110.3973 - classification_accuracy: 0.6208 57344/204800 [=======>......................] - ETA: 40s - loss: 111.5498 - classification_loss: 1.2615 - autoencoder_loss: 110.2883 - classification_accuracy: 0.6202 61440/204800 [========>.....................] - ETA: 39s - loss: 111.5200 - classification_loss: 1.2637 - autoencoder_loss: 110.2562 - classification_accuracy: 0.6195 65536/204800 [========>.....................] - ETA: 38s - loss: 111.6545 - classification_loss: 1.2625 - autoencoder_loss: 110.3920 - classification_accuracy: 0.6195 69632/204800 [=========>....................] - ETA: 37s - loss: 111.9658 - classification_loss: 1.2624 - autoencoder_loss: 110.7034 - classification_accuracy: 0.6195 73728/204800 [=========>....................] - ETA: 36s - loss: 111.8532 - classification_loss: 1.2599 - autoencoder_loss: 110.5932 - classification_accuracy: 0.6200 77824/204800 [==========>...................] - ETA: 34s - loss: 111.7503 - classification_loss: 1.2577 - autoencoder_loss: 110.4926 - classification_accuracy: 0.6206 81920/204800 [===========>..................] - ETA: 33s - loss: 111.8087 - classification_loss: 1.2576 - autoencoder_loss: 110.5512 - classification_accuracy: 0.6208 86016/204800 [===========>..................] - ETA: 32s - loss: 111.7509 - classification_loss: 1.2560 - autoencoder_loss: 110.4949 - classification_accuracy: 0.6213 90112/204800 [============>.................] - ETA: 31s - loss: 111.4951 - classification_loss: 1.2545 - autoencoder_loss: 110.2406 - classification_accuracy: 0.6217 94208/204800 [============>.................] - ETA: 30s - loss: 111.4199 - classification_loss: 1.2542 - autoencoder_loss: 110.1657 - classification_accuracy: 0.6215 98304/204800 [=============>................] - ETA: 29s - loss: 111.4722 - classification_loss: 1.2546 - autoencoder_loss: 110.2176 - classification_accuracy: 0.6212102400/204800 [==============>...............] - ETA: 28s - loss: 111.3259 - classification_loss: 1.2556 - autoencoder_loss: 110.0702 - classification_accuracy: 0.6208106496/204800 [==============>...............] - ETA: 26s - loss: 111.3649 - classification_loss: 1.2544 - autoencoder_loss: 110.1104 - classification_accuracy: 0.6212110592/204800 [===============>..............] - ETA: 25s - loss: 111.4102 - classification_loss: 1.2532 - autoencoder_loss: 110.1570 - classification_accuracy: 0.6216114688/204800 [===============>..............] - ETA: 24s - loss: 111.2555 - classification_loss: 1.2504 - autoencoder_loss: 110.0051 - classification_accuracy: 0.6223118784/204800 [================>.............] - ETA: 23s - loss: 111.4948 - classification_loss: 1.2497 - autoencoder_loss: 110.2452 - classification_accuracy: 0.6223122880/204800 [=================>............] - ETA: 22s - loss: 111.4012 - classification_loss: 1.2497 - autoencoder_loss: 110.1515 - classification_accuracy: 0.6221126976/204800 [=================>............] - ETA: 21s - loss: 111.5341 - classification_loss: 1.2494 - autoencoder_loss: 110.2848 - classification_accuracy: 0.6221131072/204800 [==================>...........] - ETA: 20s - loss: 111.6319 - classification_loss: 1.2494 - autoencoder_loss: 110.3826 - classification_accuracy: 0.6221135168/204800 [==================>...........] - ETA: 19s - loss: 111.5317 - classification_loss: 1.2490 - autoencoder_loss: 110.2826 - classification_accuracy: 0.6221139264/204800 [===================>..........] - ETA: 17s - loss: 111.5946 - classification_loss: 1.2498 - autoencoder_loss: 110.3449 - classification_accuracy: 0.6219143360/204800 [====================>.........] - ETA: 16s - loss: 111.6689 - classification_loss: 1.2498 - autoencoder_loss: 110.4191 - classification_accuracy: 0.6219147456/204800 [====================>.........] - ETA: 15s - loss: 111.6840 - classification_loss: 1.2500 - autoencoder_loss: 110.4340 - classification_accuracy: 0.6217151552/204800 [=====================>........] - ETA: 14s - loss: 111.6324 - classification_loss: 1.2501 - autoencoder_loss: 110.3823 - classification_accuracy: 0.6218155648/204800 [=====================>........] - ETA: 13s - loss: 111.9065 - classification_loss: 1.2491 - autoencoder_loss: 110.6574 - classification_accuracy: 0.6222159744/204800 [======================>.......] - ETA: 12s - loss: 111.9523 - classification_loss: 1.2484 - autoencoder_loss: 110.7039 - classification_accuracy: 0.6223163840/204800 [=======================>......] - ETA: 11s - loss: 111.9900 - classification_loss: 1.2472 - autoencoder_loss: 110.7428 - classification_accuracy: 0.6227167936/204800 [=======================>......] - ETA: 10s - loss: 111.7643 - classification_loss: 1.2456 - autoencoder_loss: 110.5187 - classification_accuracy: 0.6231172032/204800 [========================>.....] - ETA: 8s - loss: 111.6308 - classification_loss: 1.2448 - autoencoder_loss: 110.3861 - classification_accuracy: 0.6232 176128/204800 [========================>.....] - ETA: 7s - loss: 111.7284 - classification_loss: 1.2440 - autoencoder_loss: 110.4844 - classification_accuracy: 0.6234180224/204800 [=========================>....] - ETA: 6s - loss: 111.8749 - classification_loss: 1.2433 - autoencoder_loss: 110.6316 - classification_accuracy: 0.6236184320/204800 [==========================>...] - ETA: 5s - loss: 111.9238 - classification_loss: 1.2430 - autoencoder_loss: 110.6809 - classification_accuracy: 0.6238188416/204800 [==========================>...] - ETA: 4s - loss: 111.8424 - classification_loss: 1.2423 - autoencoder_loss: 110.6002 - classification_accuracy: 0.6242192512/204800 [===========================>..] - ETA: 3s - loss: 111.7662 - classification_loss: 1.2416 - autoencoder_loss: 110.5246 - classification_accuracy: 0.6245196608/204800 [===========================>..] - ETA: 2s - loss: 111.6729 - classification_loss: 1.2412 - autoencoder_loss: 110.4317 - classification_accuracy: 0.6245200704/204800 [============================>.] - ETA: 1s - loss: 111.7081 - classification_loss: 1.2411 - autoencoder_loss: 110.4669 - classification_accuracy: 0.6246WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.10396 - momentum: 0.95 
204800/204800 [==============================] - 57s 280us/sample - loss: 111.6493 - classification_loss: 1.2403 - autoencoder_loss: 110.4090 - classification_accuracy: 0.6248 - val_loss: 120.8748 - val_classification_loss: 1.1549 - val_autoencoder_loss: 119.7198 - val_classification_accuracy: 0.6569
Epoch 3/1000
  4096/204800 [..............................] - ETA: 54s - loss: 111.7705 - classification_loss: 1.2586 - autoencoder_loss: 110.5119 - classification_accuracy: 0.6191  8192/204800 [>.............................] - ETA: 52s - loss: 108.8574 - classification_loss: 1.2412 - autoencoder_loss: 107.6162 - classification_accuracy: 0.6229 12288/204800 [>.............................] - ETA: 51s - loss: 111.3411 - classification_loss: 1.2344 - autoencoder_loss: 110.1067 - classification_accuracy: 0.6243 16384/204800 [=>............................] - ETA: 51s - loss: 112.1974 - classification_loss: 1.2399 - autoencoder_loss: 110.9575 - classification_accuracy: 0.6225 20480/204800 [==>...........................] - ETA: 50s - loss: 112.5874 - classification_loss: 1.2413 - autoencoder_loss: 111.3461 - classification_accuracy: 0.6232 24576/204800 [==>...........................] - ETA: 48s - loss: 112.5440 - classification_loss: 1.2370 - autoencoder_loss: 111.3071 - classification_accuracy: 0.6247 28672/204800 [===>..........................] - ETA: 47s - loss: 112.0401 - classification_loss: 1.2349 - autoencoder_loss: 110.8052 - classification_accuracy: 0.6262 32768/204800 [===>..........................] - ETA: 46s - loss: 112.1910 - classification_loss: 1.2329 - autoencoder_loss: 110.9582 - classification_accuracy: 0.6269 36864/204800 [====>.........................] - ETA: 45s - loss: 111.7258 - classification_loss: 1.2310 - autoencoder_loss: 110.4948 - classification_accuracy: 0.6272 40960/204800 [=====>........................] - ETA: 44s - loss: 111.5029 - classification_loss: 1.2318 - autoencoder_loss: 110.2711 - classification_accuracy: 0.6272 45056/204800 [=====>........................] - ETA: 43s - loss: 111.2899 - classification_loss: 1.2299 - autoencoder_loss: 110.0600 - classification_accuracy: 0.6280 49152/204800 [======>.......................] - ETA: 42s - loss: 111.5036 - classification_loss: 1.2314 - autoencoder_loss: 110.2722 - classification_accuracy: 0.6270 53248/204800 [======>.......................] - ETA: 41s - loss: 111.6253 - classification_loss: 1.2317 - autoencoder_loss: 110.3936 - classification_accuracy: 0.6270 57344/204800 [=======>......................] - ETA: 39s - loss: 111.5185 - classification_loss: 1.2340 - autoencoder_loss: 110.2846 - classification_accuracy: 0.6264 61440/204800 [========>.....................] - ETA: 38s - loss: 111.4886 - classification_loss: 1.2359 - autoencoder_loss: 110.2527 - classification_accuracy: 0.6261 65536/204800 [========>.....................] - ETA: 37s - loss: 111.6242 - classification_loss: 1.2358 - autoencoder_loss: 110.3885 - classification_accuracy: 0.6261 69632/204800 [=========>....................] - ETA: 36s - loss: 111.9361 - classification_loss: 1.2362 - autoencoder_loss: 110.6999 - classification_accuracy: 0.6260 73728/204800 [=========>....................] - ETA: 35s - loss: 111.8248 - classification_loss: 1.2350 - autoencoder_loss: 110.5898 - classification_accuracy: 0.6264 77824/204800 [==========>...................] - ETA: 34s - loss: 111.7220 - classification_loss: 1.2328 - autoencoder_loss: 110.4892 - classification_accuracy: 0.6268 81920/204800 [===========>..................] - ETA: 33s - loss: 111.7805 - classification_loss: 1.2327 - autoencoder_loss: 110.5478 - classification_accuracy: 0.6267 86016/204800 [===========>..................] - ETA: 32s - loss: 111.7230 - classification_loss: 1.2314 - autoencoder_loss: 110.4916 - classification_accuracy: 0.6272 90112/204800 [============>.................] - ETA: 31s - loss: 111.4662 - classification_loss: 1.2291 - autoencoder_loss: 110.2372 - classification_accuracy: 0.6276 94208/204800 [============>.................] - ETA: 29s - loss: 111.3914 - classification_loss: 1.2290 - autoencoder_loss: 110.1624 - classification_accuracy: 0.6276 98304/204800 [=============>................] - ETA: 28s - loss: 111.4441 - classification_loss: 1.2300 - autoencoder_loss: 110.2141 - classification_accuracy: 0.6272102400/204800 [==============>...............] - ETA: 27s - loss: 111.2981 - classification_loss: 1.2312 - autoencoder_loss: 110.0668 - classification_accuracy: 0.6270106496/204800 [==============>...............] - ETA: 26s - loss: 111.3373 - classification_loss: 1.2303 - autoencoder_loss: 110.1070 - classification_accuracy: 0.6275110592/204800 [===============>..............] - ETA: 25s - loss: 111.3824 - classification_loss: 1.2288 - autoencoder_loss: 110.1536 - classification_accuracy: 0.6280114688/204800 [===============>..............] - ETA: 24s - loss: 111.2275 - classification_loss: 1.2258 - autoencoder_loss: 110.0017 - classification_accuracy: 0.6290118784/204800 [================>.............] - ETA: 23s - loss: 111.4673 - classification_loss: 1.2256 - autoencoder_loss: 110.2417 - classification_accuracy: 0.6290122880/204800 [=================>............] - ETA: 22s - loss: 111.3737 - classification_loss: 1.2257 - autoencoder_loss: 110.1480 - classification_accuracy: 0.6289126976/204800 [=================>............] - ETA: 21s - loss: 111.5069 - classification_loss: 1.2256 - autoencoder_loss: 110.2813 - classification_accuracy: 0.6289131072/204800 [==================>...........] - ETA: 20s - loss: 111.6044 - classification_loss: 1.2253 - autoencoder_loss: 110.3791 - classification_accuracy: 0.6289135168/204800 [==================>...........] - ETA: 18s - loss: 111.5040 - classification_loss: 1.2248 - autoencoder_loss: 110.2792 - classification_accuracy: 0.6290139264/204800 [===================>..........] - ETA: 17s - loss: 111.5670 - classification_loss: 1.2255 - autoencoder_loss: 110.3415 - classification_accuracy: 0.6288143360/204800 [====================>.........] - ETA: 16s - loss: 111.6412 - classification_loss: 1.2255 - autoencoder_loss: 110.4156 - classification_accuracy: 0.6289147456/204800 [====================>.........] - ETA: 15s - loss: 111.6563 - classification_loss: 1.2257 - autoencoder_loss: 110.4306 - classification_accuracy: 0.6289151552/204800 [=====================>........] - ETA: 14s - loss: 111.6045 - classification_loss: 1.2256 - autoencoder_loss: 110.3789 - classification_accuracy: 0.6290155648/204800 [=====================>........] - ETA: 13s - loss: 111.8786 - classification_loss: 1.2246 - autoencoder_loss: 110.6540 - classification_accuracy: 0.6293159744/204800 [======================>.......] - ETA: 12s - loss: 111.9248 - classification_loss: 1.2242 - autoencoder_loss: 110.7005 - classification_accuracy: 0.6295163840/204800 [=======================>......] - ETA: 11s - loss: 111.9624 - classification_loss: 1.2229 - autoencoder_loss: 110.7394 - classification_accuracy: 0.6298167936/204800 [=======================>......] - ETA: 10s - loss: 111.7370 - classification_loss: 1.2217 - autoencoder_loss: 110.5154 - classification_accuracy: 0.6302172032/204800 [========================>.....] - ETA: 8s - loss: 111.6034 - classification_loss: 1.2208 - autoencoder_loss: 110.3827 - classification_accuracy: 0.6305 176128/204800 [========================>.....] - ETA: 7s - loss: 111.7010 - classification_loss: 1.2200 - autoencoder_loss: 110.4810 - classification_accuracy: 0.6307180224/204800 [=========================>....] - ETA: 6s - loss: 111.8475 - classification_loss: 1.2192 - autoencoder_loss: 110.6283 - classification_accuracy: 0.6309184320/204800 [==========================>...] - ETA: 5s - loss: 111.8962 - classification_loss: 1.2187 - autoencoder_loss: 110.6775 - classification_accuracy: 0.6311188416/204800 [==========================>...] - ETA: 4s - loss: 111.8150 - classification_loss: 1.2182 - autoencoder_loss: 110.5968 - classification_accuracy: 0.6314192512/204800 [===========================>..] - ETA: 3s - loss: 111.7391 - classification_loss: 1.2178 - autoencoder_loss: 110.5213 - classification_accuracy: 0.6317196608/204800 [===========================>..] - ETA: 2s - loss: 111.6459 - classification_loss: 1.2175 - autoencoder_loss: 110.4284 - classification_accuracy: 0.6317200704/204800 [============================>.] - ETA: 1s - loss: 111.6809 - classification_loss: 1.2173 - autoencoder_loss: 110.4637 - classification_accuracy: 0.6318WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.10596 - momentum: 0.95 
204800/204800 [==============================] - 57s 279us/sample - loss: 111.6226 - classification_loss: 1.2168 - autoencoder_loss: 110.4058 - classification_accuracy: 0.6320 - val_loss: 120.8641 - val_classification_loss: 1.1478 - val_autoencoder_loss: 119.7163 - val_classification_accuracy: 0.6685
Epoch 4/1000
  4096/204800 [..............................] - ETA: 52s - loss: 111.7500 - classification_loss: 1.2407 - autoencoder_loss: 110.5093 - classification_accuracy: 0.6257  8192/204800 [>.............................] - ETA: 51s - loss: 108.8376 - classification_loss: 1.2247 - autoencoder_loss: 107.6130 - classification_accuracy: 0.6306 12288/204800 [>.............................] - ETA: 51s - loss: 111.3201 - classification_loss: 1.2162 - autoencoder_loss: 110.1039 - classification_accuracy: 0.6313 16384/204800 [=>............................] - ETA: 50s - loss: 112.1729 - classification_loss: 1.2185 - autoencoder_loss: 110.9544 - classification_accuracy: 0.6297 20480/204800 [==>...........................] - ETA: 49s - loss: 112.5620 - classification_loss: 1.2190 - autoencoder_loss: 111.3431 - classification_accuracy: 0.6304 24576/204800 [==>...........................] - ETA: 48s - loss: 112.5205 - classification_loss: 1.2162 - autoencoder_loss: 111.3043 - classification_accuracy: 0.6311 28672/204800 [===>..........................] - ETA: 47s - loss: 112.0147 - classification_loss: 1.2121 - autoencoder_loss: 110.8026 - classification_accuracy: 0.6323 32768/204800 [===>..........................] - ETA: 46s - loss: 112.1653 - classification_loss: 1.2099 - autoencoder_loss: 110.9554 - classification_accuracy: 0.6339 36864/204800 [====>.........................] - ETA: 45s - loss: 111.6979 - classification_loss: 1.2059 - autoencoder_loss: 110.4920 - classification_accuracy: 0.6345 40960/204800 [=====>........................] - ETA: 44s - loss: 111.4760 - classification_loss: 1.2075 - autoencoder_loss: 110.2685 - classification_accuracy: 0.6345 45056/204800 [=====>........................] - ETA: 43s - loss: 111.2627 - classification_loss: 1.2053 - autoencoder_loss: 110.0573 - classification_accuracy: 0.6351 49152/204800 [======>.......................] - ETA: 42s - loss: 111.4768 - classification_loss: 1.2073 - autoencoder_loss: 110.2695 - classification_accuracy: 0.6340 53248/204800 [======>.......................] - ETA: 41s - loss: 111.5976 - classification_loss: 1.2068 - autoencoder_loss: 110.3908 - classification_accuracy: 0.6336 57344/204800 [=======>......................] - ETA: 40s - loss: 111.4905 - classification_loss: 1.2086 - autoencoder_loss: 110.2819 - classification_accuracy: 0.6336 61440/204800 [========>.....................] - ETA: 38s - loss: 111.4610 - classification_loss: 1.2110 - autoencoder_loss: 110.2499 - classification_accuracy: 0.6328 65536/204800 [========>.....................] - ETA: 37s - loss: 111.5960 - classification_loss: 1.2103 - autoencoder_loss: 110.3858 - classification_accuracy: 0.6329 69632/204800 [=========>....................] - ETA: 36s - loss: 111.9082 - classification_loss: 1.2109 - autoencoder_loss: 110.6973 - classification_accuracy: 0.6328 73728/204800 [=========>....................] - ETA: 35s - loss: 111.7959 - classification_loss: 1.2087 - autoencoder_loss: 110.5872 - classification_accuracy: 0.6335 77824/204800 [==========>...................] - ETA: 34s - loss: 111.6934 - classification_loss: 1.2068 - autoencoder_loss: 110.4866 - classification_accuracy: 0.6340 81920/204800 [===========>..................] - ETA: 33s - loss: 111.7518 - classification_loss: 1.2067 - autoencoder_loss: 110.5451 - classification_accuracy: 0.6340 86016/204800 [===========>..................] - ETA: 32s - loss: 111.6940 - classification_loss: 1.2051 - autoencoder_loss: 110.4889 - classification_accuracy: 0.6345 90112/204800 [============>.................] - ETA: 31s - loss: 111.4380 - classification_loss: 1.2034 - autoencoder_loss: 110.2346 - classification_accuracy: 0.6349 94208/204800 [============>.................] - ETA: 30s - loss: 111.3628 - classification_loss: 1.2030 - autoencoder_loss: 110.1598 - classification_accuracy: 0.6349 98304/204800 [=============>................] - ETA: 29s - loss: 111.4158 - classification_loss: 1.2042 - autoencoder_loss: 110.2117 - classification_accuracy: 0.6342102400/204800 [==============>...............] - ETA: 27s - loss: 111.2696 - classification_loss: 1.2053 - autoencoder_loss: 110.0643 - classification_accuracy: 0.6340106496/204800 [==============>...............] - ETA: 26s - loss: 111.3089 - classification_loss: 1.2044 - autoencoder_loss: 110.1045 - classification_accuracy: 0.6343110592/204800 [===============>..............] - ETA: 25s - loss: 111.3541 - classification_loss: 1.2031 - autoencoder_loss: 110.1510 - classification_accuracy: 0.6348114688/204800 [===============>..............] - ETA: 24s - loss: 111.1995 - classification_loss: 1.2004 - autoencoder_loss: 109.9992 - classification_accuracy: 0.6357118784/204800 [================>.............] - ETA: 23s - loss: 111.4390 - classification_loss: 1.1999 - autoencoder_loss: 110.2392 - classification_accuracy: 0.6358122880/204800 [=================>............] - ETA: 22s - loss: 111.3457 - classification_loss: 1.2002 - autoencoder_loss: 110.1455 - classification_accuracy: 0.6357126976/204800 [=================>............] - ETA: 21s - loss: 111.4789 - classification_loss: 1.2001 - autoencoder_loss: 110.2788 - classification_accuracy: 0.6355131072/204800 [==================>...........] - ETA: 20s - loss: 111.5771 - classification_loss: 1.2005 - autoencoder_loss: 110.3766 - classification_accuracy: 0.6354135168/204800 [==================>...........] - ETA: 18s - loss: 111.4768 - classification_loss: 1.2001 - autoencoder_loss: 110.2767 - classification_accuracy: 0.6356139264/204800 [===================>..........] - ETA: 17s - loss: 111.5399 - classification_loss: 1.2009 - autoencoder_loss: 110.3390 - classification_accuracy: 0.6352143360/204800 [====================>.........] - ETA: 16s - loss: 111.6145 - classification_loss: 1.2013 - autoencoder_loss: 110.4132 - classification_accuracy: 0.6352147456/204800 [====================>.........] - ETA: 15s - loss: 111.6300 - classification_loss: 1.2018 - autoencoder_loss: 110.4282 - classification_accuracy: 0.6350151552/204800 [=====================>........] - ETA: 14s - loss: 111.5786 - classification_loss: 1.2021 - autoencoder_loss: 110.3765 - classification_accuracy: 0.6351155648/204800 [=====================>........] - ETA: 13s - loss: 111.8529 - classification_loss: 1.2014 - autoencoder_loss: 110.6515 - classification_accuracy: 0.6352159744/204800 [======================>.......] - ETA: 12s - loss: 111.8988 - classification_loss: 1.2008 - autoencoder_loss: 110.6980 - classification_accuracy: 0.6354163840/204800 [=======================>......] - ETA: 11s - loss: 111.9365 - classification_loss: 1.1996 - autoencoder_loss: 110.7370 - classification_accuracy: 0.6358167936/204800 [=======================>......] - ETA: 10s - loss: 111.7110 - classification_loss: 1.1982 - autoencoder_loss: 110.5128 - classification_accuracy: 0.6363172032/204800 [========================>.....] - ETA: 8s - loss: 111.5774 - classification_loss: 1.1972 - autoencoder_loss: 110.3802 - classification_accuracy: 0.6366 176128/204800 [========================>.....] - ETA: 7s - loss: 111.6751 - classification_loss: 1.1966 - autoencoder_loss: 110.4785 - classification_accuracy: 0.6367180224/204800 [=========================>....] - ETA: 6s - loss: 111.8218 - classification_loss: 1.1961 - autoencoder_loss: 110.6257 - classification_accuracy: 0.6369184320/204800 [==========================>...] - ETA: 5s - loss: 111.8704 - classification_loss: 1.1954 - autoencoder_loss: 110.6750 - classification_accuracy: 0.6372188416/204800 [==========================>...] - ETA: 4s - loss: 111.7892 - classification_loss: 1.1949 - autoencoder_loss: 110.5944 - classification_accuracy: 0.6373192512/204800 [===========================>..] - ETA: 3s - loss: 111.7133 - classification_loss: 1.1945 - autoencoder_loss: 110.5188 - classification_accuracy: 0.6375196608/204800 [===========================>..] - ETA: 2s - loss: 111.6203 - classification_loss: 1.1944 - autoencoder_loss: 110.4260 - classification_accuracy: 0.6374200704/204800 [============================>.] - ETA: 1s - loss: 111.6555 - classification_loss: 1.1943 - autoencoder_loss: 110.4612 - classification_accuracy: 0.6374WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.10796 - momentum: 0.95 
204800/204800 [==============================] - 57s 279us/sample - loss: 111.5972 - classification_loss: 1.1938 - autoencoder_loss: 110.4033 - classification_accuracy: 0.6376 - val_loss: 120.8674 - val_classification_loss: 1.1480 - val_autoencoder_loss: 119.7194 - val_classification_accuracy: 0.6750
Epoch 5/1000
  4096/204800 [..............................] - ETA: 54s - loss: 111.7282 - classification_loss: 1.2215 - autoencoder_loss: 110.5067 - classification_accuracy: 0.6313  8192/204800 [>.............................] - ETA: 53s - loss: 108.8243 - classification_loss: 1.2135 - autoencoder_loss: 107.6109 - classification_accuracy: 0.6323 12288/204800 [>.............................] - ETA: 52s - loss: 111.3028 - classification_loss: 1.2014 - autoencoder_loss: 110.1014 - classification_accuracy: 0.6326 16384/204800 [=>............................] - ETA: 51s - loss: 112.1583 - classification_loss: 1.2056 - autoencoder_loss: 110.9527 - classification_accuracy: 0.6329 20480/204800 [==>...........................] - ETA: 50s - loss: 112.5456 - classification_loss: 1.2045 - autoencoder_loss: 111.3411 - classification_accuracy: 0.6342 24576/204800 [==>...........................] - ETA: 48s - loss: 112.5025 - classification_loss: 1.2002 - autoencoder_loss: 111.3023 - classification_accuracy: 0.6362 28672/204800 [===>..........................] - ETA: 47s - loss: 111.9961 - classification_loss: 1.1955 - autoencoder_loss: 110.8006 - classification_accuracy: 0.6380 32768/204800 [===>..........................] - ETA: 46s - loss: 112.1462 - classification_loss: 1.1926 - autoencoder_loss: 110.9535 - classification_accuracy: 0.6390 36864/204800 [====>.........................] - ETA: 45s - loss: 111.6797 - classification_loss: 1.1897 - autoencoder_loss: 110.4899 - classification_accuracy: 0.6400 40960/204800 [=====>........................] - ETA: 44s - loss: 111.4569 - classification_loss: 1.1907 - autoencoder_loss: 110.2662 - classification_accuracy: 0.6399 45056/204800 [=====>........................] - ETA: 43s - loss: 111.2434 - classification_loss: 1.1884 - autoencoder_loss: 110.0550 - classification_accuracy: 0.6402 49152/204800 [======>.......................] - ETA: 42s - loss: 111.4564 - classification_loss: 1.1894 - autoencoder_loss: 110.2670 - classification_accuracy: 0.6396 53248/204800 [======>.......................] - ETA: 41s - loss: 111.5783 - classification_loss: 1.1899 - autoencoder_loss: 110.3884 - classification_accuracy: 0.6395 57344/204800 [=======>......................] - ETA: 40s - loss: 111.4711 - classification_loss: 1.1917 - autoencoder_loss: 110.2794 - classification_accuracy: 0.6388 61440/204800 [========>.....................] - ETA: 39s - loss: 111.4413 - classification_loss: 1.1939 - autoencoder_loss: 110.2474 - classification_accuracy: 0.6379 65536/204800 [========>.....................] - ETA: 38s - loss: 111.5770 - classification_loss: 1.1937 - autoencoder_loss: 110.3833 - classification_accuracy: 0.6377 69632/204800 [=========>....................] - ETA: 36s - loss: 111.8900 - classification_loss: 1.1953 - autoencoder_loss: 110.6948 - classification_accuracy: 0.6371 73728/204800 [=========>....................] - ETA: 35s - loss: 111.7785 - classification_loss: 1.1938 - autoencoder_loss: 110.5846 - classification_accuracy: 0.6374 77824/204800 [==========>...................] - ETA: 34s - loss: 111.6754 - classification_loss: 1.1916 - autoencoder_loss: 110.4838 - classification_accuracy: 0.6380 81920/204800 [===========>..................] - ETA: 33s - loss: 111.7344 - classification_loss: 1.1919 - autoencoder_loss: 110.5424 - classification_accuracy: 0.6376 86016/204800 [===========>..................] - ETA: 32s - loss: 111.6767 - classification_loss: 1.1904 - autoencoder_loss: 110.4863 - classification_accuracy: 0.6381 90112/204800 [============>.................] - ETA: 31s - loss: 111.4207 - classification_loss: 1.1886 - autoencoder_loss: 110.2321 - classification_accuracy: 0.6388 94208/204800 [============>.................] - ETA: 30s - loss: 111.3458 - classification_loss: 1.1885 - autoencoder_loss: 110.1573 - classification_accuracy: 0.6384 98304/204800 [=============>................] - ETA: 29s - loss: 111.3981 - classification_loss: 1.1890 - autoencoder_loss: 110.2091 - classification_accuracy: 0.6383102400/204800 [==============>...............] - ETA: 27s - loss: 111.2516 - classification_loss: 1.1899 - autoencoder_loss: 110.0617 - classification_accuracy: 0.6382106496/204800 [==============>...............] - ETA: 26s - loss: 111.2910 - classification_loss: 1.1892 - autoencoder_loss: 110.1017 - classification_accuracy: 0.6386110592/204800 [===============>..............] - ETA: 25s - loss: 111.3361 - classification_loss: 1.1877 - autoencoder_loss: 110.1484 - classification_accuracy: 0.6390114688/204800 [===============>..............] - ETA: 24s - loss: 111.1818 - classification_loss: 1.1853 - autoencoder_loss: 109.9965 - classification_accuracy: 0.6396118784/204800 [================>.............] - ETA: 23s - loss: 111.4215 - classification_loss: 1.1851 - autoencoder_loss: 110.2364 - classification_accuracy: 0.6398122880/204800 [=================>............] - ETA: 22s - loss: 111.3278 - classification_loss: 1.1849 - autoencoder_loss: 110.1429 - classification_accuracy: 0.6398126976/204800 [=================>............] - ETA: 21s - loss: 111.4612 - classification_loss: 1.1851 - autoencoder_loss: 110.2761 - classification_accuracy: 0.6396131072/204800 [==================>...........] - ETA: 20s - loss: 111.5588 - classification_loss: 1.1850 - autoencoder_loss: 110.3738 - classification_accuracy: 0.6396135168/204800 [==================>...........] - ETA: 19s - loss: 111.4589 - classification_loss: 1.1849 - autoencoder_loss: 110.2740 - classification_accuracy: 0.6395139264/204800 [===================>..........] - ETA: 17s - loss: 111.5225 - classification_loss: 1.1863 - autoencoder_loss: 110.3362 - classification_accuracy: 0.6391143360/204800 [====================>.........] - ETA: 16s - loss: 111.5967 - classification_loss: 1.1865 - autoencoder_loss: 110.4102 - classification_accuracy: 0.6391147456/204800 [====================>.........] - ETA: 15s - loss: 111.6118 - classification_loss: 1.1866 - autoencoder_loss: 110.4252 - classification_accuracy: 0.6389151552/204800 [=====================>........] - ETA: 14s - loss: 111.5601 - classification_loss: 1.1867 - autoencoder_loss: 110.3734 - classification_accuracy: 0.6389155648/204800 [=====================>........] - ETA: 13s - loss: 111.8344 - classification_loss: 1.1859 - autoencoder_loss: 110.6485 - classification_accuracy: 0.6391159744/204800 [======================>.......] - ETA: 12s - loss: 111.8807 - classification_loss: 1.1857 - autoencoder_loss: 110.6950 - classification_accuracy: 0.6391163840/204800 [=======================>......] - ETA: 11s - loss: 111.9184 - classification_loss: 1.1845 - autoencoder_loss: 110.7339 - classification_accuracy: 0.6394167936/204800 [=======================>......] - ETA: 10s - loss: 111.6933 - classification_loss: 1.1834 - autoencoder_loss: 110.5099 - classification_accuracy: 0.6397172032/204800 [========================>.....] - ETA: 8s - loss: 111.5600 - classification_loss: 1.1828 - autoencoder_loss: 110.3772 - classification_accuracy: 0.6399 176128/204800 [========================>.....] - ETA: 7s - loss: 111.6576 - classification_loss: 1.1821 - autoencoder_loss: 110.4755 - classification_accuracy: 0.6401180224/204800 [=========================>....] - ETA: 6s - loss: 111.8043 - classification_loss: 1.1816 - autoencoder_loss: 110.6227 - classification_accuracy: 0.6404184320/204800 [==========================>...] - ETA: 5s - loss: 111.8531 - classification_loss: 1.1811 - autoencoder_loss: 110.6720 - classification_accuracy: 0.6406188416/204800 [==========================>...] - ETA: 4s - loss: 111.7724 - classification_loss: 1.1810 - autoencoder_loss: 110.5914 - classification_accuracy: 0.6408192512/204800 [===========================>..] - ETA: 3s - loss: 111.6965 - classification_loss: 1.1807 - autoencoder_loss: 110.5158 - classification_accuracy: 0.6409196608/204800 [===========================>..] - ETA: 2s - loss: 111.6036 - classification_loss: 1.1807 - autoencoder_loss: 110.4229 - classification_accuracy: 0.6409200704/204800 [============================>.] - ETA: 1s - loss: 111.6389 - classification_loss: 1.1808 - autoencoder_loss: 110.4581 - classification_accuracy: 0.6409WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.10996 - momentum: 0.95 
204800/204800 [==============================] - 57s 280us/sample - loss: 111.5806 - classification_loss: 1.1804 - autoencoder_loss: 110.4002 - classification_accuracy: 0.6410 - val_loss: 120.8375 - val_classification_loss: 1.1205 - val_autoencoder_loss: 119.7170 - val_classification_accuracy: 0.6804
Epoch 6/1000
  4096/204800 [..............................] - ETA: 56s - loss: 111.7088 - classification_loss: 1.2063 - autoencoder_loss: 110.5024 - classification_accuracy: 0.6304  8192/204800 [>.............................] - ETA: 54s - loss: 108.7972 - classification_loss: 1.1895 - autoencoder_loss: 107.6077 - classification_accuracy: 0.6385 12288/204800 [>.............................] - ETA: 53s - loss: 111.2806 - classification_loss: 1.1833 - autoencoder_loss: 110.0973 - classification_accuracy: 0.6398 16384/204800 [=>............................] - ETA: 52s - loss: 112.1356 - classification_loss: 1.1879 - autoencoder_loss: 110.9477 - classification_accuracy: 0.6391 20480/204800 [==>...........................] - ETA: 51s - loss: 112.5255 - classification_loss: 1.1892 - autoencoder_loss: 111.3363 - classification_accuracy: 0.6391 24576/204800 [==>...........................] - ETA: 49s - loss: 112.4836 - classification_loss: 1.1857 - autoencoder_loss: 111.2979 - classification_accuracy: 0.6402 28672/204800 [===>..........................] - ETA: 48s - loss: 111.9786 - classification_loss: 1.1826 - autoencoder_loss: 110.7961 - classification_accuracy: 0.6421 32768/204800 [===>..........................] - ETA: 47s - loss: 112.1287 - classification_loss: 1.1799 - autoencoder_loss: 110.9488 - classification_accuracy: 0.6424 36864/204800 [====>.........................] - ETA: 45s - loss: 111.6621 - classification_loss: 1.1765 - autoencoder_loss: 110.4856 - classification_accuracy: 0.6430 40960/204800 [=====>........................] - ETA: 44s - loss: 111.4399 - classification_loss: 1.1779 - autoencoder_loss: 110.2619 - classification_accuracy: 0.6423 45056/204800 [=====>........................] - ETA: 43s - loss: 111.2272 - classification_loss: 1.1762 - autoencoder_loss: 110.0509 - classification_accuracy: 0.6428 49152/204800 [======>.......................] - ETA: 42s - loss: 111.4406 - classification_loss: 1.1778 - autoencoder_loss: 110.2628 - classification_accuracy: 0.6420 53248/204800 [======>.......................] - ETA: 41s - loss: 111.5623 - classification_loss: 1.1781 - autoencoder_loss: 110.3842 - classification_accuracy: 0.6416 57344/204800 [=======>......................] - ETA: 40s - loss: 111.4554 - classification_loss: 1.1802 - autoencoder_loss: 110.2752 - classification_accuracy: 0.6412 61440/204800 [========>.....................] - ETA: 39s - loss: 111.4265 - classification_loss: 1.1831 - autoencoder_loss: 110.2434 - classification_accuracy: 0.6403 65536/204800 [========>.....................] - ETA: 38s - loss: 111.5616 - classification_loss: 1.1825 - autoencoder_loss: 110.3790 - classification_accuracy: 0.6405 69632/204800 [=========>....................] - ETA: 37s - loss: 111.8737 - classification_loss: 1.1834 - autoencoder_loss: 110.6903 - classification_accuracy: 0.6401 73728/204800 [=========>....................] - ETA: 36s - loss: 111.7615 - classification_loss: 1.1813 - autoencoder_loss: 110.5802 - classification_accuracy: 0.6403 77824/204800 [==========>...................] - ETA: 35s - loss: 111.6592 - classification_loss: 1.1797 - autoencoder_loss: 110.4795 - classification_accuracy: 0.6409 81920/204800 [===========>..................] - ETA: 33s - loss: 111.7181 - classification_loss: 1.1799 - autoencoder_loss: 110.5382 - classification_accuracy: 0.6406 86016/204800 [===========>..................] - ETA: 32s - loss: 111.6603 - classification_loss: 1.1785 - autoencoder_loss: 110.4818 - classification_accuracy: 0.6409 90112/204800 [============>.................] - ETA: 31s - loss: 111.4042 - classification_loss: 1.1768 - autoencoder_loss: 110.2274 - classification_accuracy: 0.6415 94208/204800 [============>.................] - ETA: 30s - loss: 111.3299 - classification_loss: 1.1774 - autoencoder_loss: 110.1525 - classification_accuracy: 0.6413 98304/204800 [=============>................] - ETA: 29s - loss: 111.3831 - classification_loss: 1.1787 - autoencoder_loss: 110.2044 - classification_accuracy: 0.6409102400/204800 [==============>...............] - ETA: 28s - loss: 111.2364 - classification_loss: 1.1794 - autoencoder_loss: 110.0570 - classification_accuracy: 0.6406106496/204800 [==============>...............] - ETA: 27s - loss: 111.2760 - classification_loss: 1.1790 - autoencoder_loss: 110.0970 - classification_accuracy: 0.6408110592/204800 [===============>..............] - ETA: 25s - loss: 111.3216 - classification_loss: 1.1780 - autoencoder_loss: 110.1436 - classification_accuracy: 0.6412114688/204800 [===============>..............] - ETA: 24s - loss: 111.1672 - classification_loss: 1.1753 - autoencoder_loss: 109.9919 - classification_accuracy: 0.6419118784/204800 [================>.............] - ETA: 23s - loss: 111.4071 - classification_loss: 1.1753 - autoencoder_loss: 110.2318 - classification_accuracy: 0.6419122880/204800 [=================>............] - ETA: 22s - loss: 111.3134 - classification_loss: 1.1752 - autoencoder_loss: 110.1382 - classification_accuracy: 0.6420126976/204800 [=================>............] - ETA: 21s - loss: 111.4465 - classification_loss: 1.1751 - autoencoder_loss: 110.2714 - classification_accuracy: 0.6419131072/204800 [==================>...........] - ETA: 20s - loss: 111.5450 - classification_loss: 1.1756 - autoencoder_loss: 110.3693 - classification_accuracy: 0.6417135168/204800 [==================>...........] - ETA: 19s - loss: 111.4452 - classification_loss: 1.1757 - autoencoder_loss: 110.2695 - classification_accuracy: 0.6416139264/204800 [===================>..........] - ETA: 17s - loss: 111.5086 - classification_loss: 1.1768 - autoencoder_loss: 110.3318 - classification_accuracy: 0.6414143360/204800 [====================>.........] - ETA: 16s - loss: 111.5828 - classification_loss: 1.1769 - autoencoder_loss: 110.4059 - classification_accuracy: 0.6414147456/204800 [====================>.........] - ETA: 15s - loss: 111.5983 - classification_loss: 1.1774 - autoencoder_loss: 110.4209 - classification_accuracy: 0.6410151552/204800 [=====================>........] - ETA: 14s - loss: 111.5465 - classification_loss: 1.1773 - autoencoder_loss: 110.3692 - classification_accuracy: 0.6411155648/204800 [=====================>........] - ETA: 13s - loss: 111.8208 - classification_loss: 1.1766 - autoencoder_loss: 110.6442 - classification_accuracy: 0.6413159744/204800 [======================>.......] - ETA: 12s - loss: 111.8669 - classification_loss: 1.1762 - autoencoder_loss: 110.6907 - classification_accuracy: 0.6414163840/204800 [=======================>......] - ETA: 11s - loss: 111.9047 - classification_loss: 1.1751 - autoencoder_loss: 110.7296 - classification_accuracy: 0.6417167936/204800 [=======================>......] - ETA: 10s - loss: 111.6796 - classification_loss: 1.1740 - autoencoder_loss: 110.5056 - classification_accuracy: 0.6422172032/204800 [========================>.....] - ETA: 8s - loss: 111.5464 - classification_loss: 1.1734 - autoencoder_loss: 110.3730 - classification_accuracy: 0.6425 176128/204800 [========================>.....] - ETA: 7s - loss: 111.6443 - classification_loss: 1.1730 - autoencoder_loss: 110.4714 - classification_accuracy: 0.6425180224/204800 [=========================>....] - ETA: 6s - loss: 111.7910 - classification_loss: 1.1725 - autoencoder_loss: 110.6185 - classification_accuracy: 0.6427184320/204800 [==========================>...] - ETA: 5s - loss: 111.8394 - classification_loss: 1.1716 - autoencoder_loss: 110.6678 - classification_accuracy: 0.6428188416/204800 [==========================>...] - ETA: 4s - loss: 111.7583 - classification_loss: 1.1713 - autoencoder_loss: 110.5870 - classification_accuracy: 0.6429192512/204800 [===========================>..] - ETA: 3s - loss: 111.6826 - classification_loss: 1.1711 - autoencoder_loss: 110.5115 - classification_accuracy: 0.6431196608/204800 [===========================>..] - ETA: 2s - loss: 111.5897 - classification_loss: 1.1710 - autoencoder_loss: 110.4187 - classification_accuracy: 0.6430200704/204800 [============================>.] - ETA: 1s - loss: 111.6247 - classification_loss: 1.1709 - autoencoder_loss: 110.4539 - classification_accuracy: 0.6430WARNING:tensorflow:Early stopping conditioned on metric `val_;loss` which is not available. Available metrics are: loss,classification_loss,autoencoder_loss,classification_accuracy,val_loss,val_classification_loss,val_autoencoder_loss,val_classification_accuracy
 - lr: 0.11196 - momentum: 0.95 
204800/204800 [==============================] - 57s 279us/sample - loss: 111.5665 - classification_loss: 1.1705 - autoencoder_loss: 110.3960 - classification_accuracy: 0.6432 - val_loss: 120.8589 - val_classification_loss: 1.1355 - val_autoencoder_loss: 119.7233 - val_classification_accuracy: 0.6803
Epoch 7/1000
  4096/204800 [..............................] - ETA: 51s - loss: 111.6920 - classification_loss: 1.1970 - autoencoder_loss: 110.4950 - classification_accuracy: 0.6340  8192/204800 [>.............................] - ETA: 51s - loss: 108.7819 - classification_loss: 1.1823 - autoencoder_loss: 107.5996 - classification_accuracy: 0.6407 12288/204800 [>.............................] - ETA: 51s - loss: 111.2619 - classification_loss: 1.1710 - autoencoder_loss: 110.0909 - classification_accuracy: 0.6432 16384/204800 [=>............................] - ETA: 49s - loss: 112.1210 - classification_loss: 1.1790 - autoencoder_loss: 110.9420 - classification_accuracy: 0.6418 20480/204800 [==>...........................] - ETA: 49s - loss: 112.5115 - classification_loss: 1.1807 - autoencoder_loss: 111.3308 - classification_accuracy: 0.6403 24576/204800 [==>...........................] - ETA: 48s - loss: 112.4692 - classification_loss: 1.1764 - autoencoder_loss: 111.2928 - classification_accuracy: 0.6420 28672/204800 [===>..........................] - ETA: 47s - loss: 111.9661 - classification_loss: 1.1750 - autoencoder_loss: 110.7911 - classification_accuracy: 0.6434 32768/204800 [===>..........................] - ETA: 46s - loss: 112.1156 - classification_loss: 1.1718 - autoencoder_loss: 110.9438 - classification_accuracy: 0.6443 36864/204800 [====>.........................] - ETA: 44s - loss: 111.6503 - classification_loss: 1.1696 - autoencoder_loss: 110.4807 - classification_accuracy: 0.6446 40960/204800 [=====>........................] - ETA: 43s - loss: 111.4288 - classification_loss: 1.1714 - autoencoder_loss: 110.2573 - classification_accuracy: 0.6444 45056/204800 [=====>........................] - ETA: 42s - loss: 111.2157 - classification_loss: 1.1697 - autoencoder_loss: 110.0460 - classification_accuracy: 0.6447 49152/204800 [======>.......................] - ETA: 41s - loss: 111.4297 - classification_loss: 1.1716 - autoencoder_loss: 110.2580 - classification_accuracy: 0.6437 53248/204800 [======>.......................] - ETA: 40s - loss: 111.5511 - classification_loss: 1.1714 - autoencoder_loss: 110.3797 - classification_accuracy: 0.6433 57344/204800 [=======>......................] - ETA: 39s - loss: 111.4446 - classification_loss: 1.1739 - autoencoder_loss: 110.2707 - classification_accuracy: 0.6428 61440/204800 [========>.....................] - ETA: 38s - loss: 111.4152 - classification_loss: 1.1763 - autoencoder_loss: 110.2389 - classification_accuracy: 0.6423 65536/204800 [========>.....................] - ETA: 37s - loss: 111.5498 - classification_loss: 1.1754 - autoencoder_loss: 110.3744 - classification_accuracy: 0.6426 69632/204800 [=========>....................] - ETA: 36s - loss: 111.8628 - classification_loss: 1.1767 - autoencoder_loss: 110.6861 - classification_accuracy: 0.6423 73728/204800 [=========>....................] - ETA: 35s - loss: 111.7518 - classification_loss: 1.1757 - autoencoder_loss: 110.5762 - classification_accuracy: 0.6428 77824/204800 [==========>...................] - ETA: 34s - loss: 111.6495 - classification_loss: 1.1743 - autoencoder_loss: 110.4752 - classification_accuracy: 0.6429 81920/204800 [===========>..................] - ETA: 33s - loss: 111.7088 - classification_loss: 1.1749 - autoencoder_loss: 110.5339 - classification_accuracy: 0.6427 86016/204800 [===========>..................] - ETA: 32s - loss: 111.6511 - classification_loss: 1.1735 - autoencoder_loss: 110.4777 - classification_accuracy: 0.6431 90112/204800 [============>.................] - ETA: 30s - loss: 111.3946 - classification_loss: 1.1714 - autoencoder_loss: 110.2233 - classification_accuracy: 0.6436 94208/204800 [============>.................] - ETA: 29s - loss: 111.3198 - classification_loss: 1.1712 - autoencoder_loss: 110.1486 - classification_accuracy: 0.6435 98304/204800 [=============>................] - ETA: 28s - loss: 111.3725 - classification_loss: 1.1720 - autoencoder_loss: 110.2005 - classification_accuracy: 0.6431102400/204800 [==============>...............] - ETA: 27s - loss: 111.2263 - classification_loss: 1.1730 - autoencoder_loss: 110.0533 - classification_accuracy: 0.6428106496/204800 [==============>...............] - ETA: 26s - loss: 111.2654 - classification_loss: 1.1721 - autoencoder_loss: 110.0933 - classification_accuracy: 0.6434110592/204800 [===============>..............] - ETA: 25s - loss: 111.3109 - classification_loss: 1.1709 - autoencoder_loss: 110.1399 - classification_accuracy: 0.6437114688/204800 [===============>..............] - ETA: 24s - loss: 111.1569 - classification_loss: 1.1687 - autoencoder_loss: 109.9882 - classification_accuracy: 0.6443118784/204800 [================>.............] - ETA: 23s - loss: 111.3964 - classification_loss: 1.1682 - autoencoder_loss: 110.2282 - classification_accuracy: 0.6443122880/204800 [=================>............] - ETA: 22s - loss: 111.3027 - classification_loss: 1.1682 - autoencoder_loss: 110.1346 - classification_accuracy: 0.6444126976/204800 [=================>............] - ETA: 20s - loss: 111.4359 - classification_loss: 1.1682 - autoencoder_loss: 110.2677 - classification_accuracy: 0.6442131072/204800 [==================>...........] - ETA: 19s - loss: 111.5340 - classification_loss: 1.1684 - autoencoder_loss: 110.3655 - classification_accuracy: 0.6441slurmstepd: error: *** JOB 9017718 ON va003 CANCELLED AT 2020-02-03T23:17:49 ***
